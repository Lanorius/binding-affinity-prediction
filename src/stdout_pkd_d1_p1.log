Sender: LSF System <lsfadmin@lsf-server-3.rostclust>
Subject: Job 13156: <dg_prediction_pkd_d1_p1> in cluster <rost_lsf_cluster_1> Done

Job <dg_prediction_pkd_d1_p1> was submitted from host <lsf-master-1.rostclust> by user <giessing> in cluster <rost_lsf_cluster_1> at Wed Dec 15 08:03:36 2021
Job was executed on host(s) <lsf-server-3.rostclust>, in queue <low-end-normal>, as user <giessing> in cluster <rost_lsf_cluster_1> at Wed Dec 15 08:03:36 2021
</mnt/home/giessing> was used as the home directory.
</mnt/project/protdrugaffinity/dg/binding-affinity-prediction/src> was used as the working directory.
Started at Wed Dec 15 08:03:36 2021
Terminated at Thu Dec 16 02:00:44 2021
Results reported at Thu Dec 16 02:00:44 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python binding_prediction.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   147594.80 sec.
    Max Memory :                                 1714 MB
    Average Memory :                             1654.25 MB
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                26
    Run time :                                   64627 sec.
    Turnaround time :                            64628 sec.

The output (if any) follows:

(['pkd', 'Davis'], 'chemVAE', <Section: INPUT FILES>, True, 1, False, False)
Using device: cuda
[320, 0.006900000000000001, 110]
[320, 0.006900000000000001, 110]
[320, 0.006900000000000001, 110]
[320, 0.006900000000000001, 110]
[320, 0.006900000000000001, 110]
[320, 0.006900000000000001, 110]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
[110, 0.0088, 270]
Finished Tuning
0.4261557731478642
[110, 0.0088, 270]
[1] loss: 6334.8453371
[2] loss: 5237.8721651
[3] loss: 5237.8721651
[4] loss: 5237.8721651
[5] loss: 5237.8721651
[6] loss: 5237.8721651
[7] loss: 5237.8721651
[8] loss: 5237.8721651
[9] loss: 5237.8721651
[10] loss: 5237.8721651
[11] loss: 5237.8721651
[12] loss: 5237.8721651
[13] loss: 5237.8721651
[14] loss: 5237.8721651
[15] loss: 5237.8721651
[16] loss: 5237.8721651
[17] loss: 5237.8721651
[18] loss: 5237.8721651
[19] loss: 5237.8721651
[20] loss: 5237.8721651
[21] loss: 5237.8721651
[22] loss: 5237.8721651
[23] loss: 5237.8721651
[24] loss: 5237.8721651
[25] loss: 5237.8721651
[26] loss: 5237.8721651
[27] loss: 5237.8721651
[28] loss: 5237.8721651
[29] loss: 5237.8721651
[30] loss: 5237.8721651
[31] loss: 5237.8721651
[32] loss: 5237.8721651
[33] loss: 5237.8721651
[34] loss: 5237.8721651
[35] loss: 5237.8721651
[36] loss: 5237.8721651
[37] loss: 5237.8721651
[38] loss: 5237.8721651
[39] loss: 5237.8721651
[40] loss: 5237.8721651
[41] loss: 5237.8721651
[42] loss: 5237.8721651
[43] loss: 5237.8721651
[44] loss: 5237.8721651
[45] loss: 5237.8721651
[46] loss: 5237.8721651
[47] loss: 5237.8721651
[48] loss: 5237.8721651
[49] loss: 5237.8721651
[50] loss: 5237.8721651
[51] loss: 5237.8721651
[52] loss: 5237.8721651
[53] loss: 5237.8721651
[54] loss: 5237.8721651
[55] loss: 5237.8721651
[56] loss: 5237.8721651
[57] loss: 5237.8721651
[58] loss: 5237.8721651
[59] loss: 5237.8721651
[60] loss: 5237.8721651
[61] loss: 5237.8721651
[62] loss: 5237.8721651
[63] loss: 5237.8721651
[64] loss: 5237.8721651
[65] loss: 5237.8721651
[66] loss: 5237.8721651
[67] loss: 5237.8721651
[68] loss: 5237.8721651
[69] loss: 5237.8721651
[70] loss: 5237.8721651
[71] loss: 5237.8721651
[72] loss: 5237.8721651
[73] loss: 5237.8721651
[74] loss: 5237.8721651
[75] loss: 5237.8721651
[76] loss: 5237.8721651
[77] loss: 5237.8721651
[78] loss: 5237.8721651
[79] loss: 5237.8721651
[80] loss: 5237.8721651
[81] loss: 5237.8721651
[82] loss: 5237.8721651
[83] loss: 5237.8721651
[84] loss: 5237.8721651
[85] loss: 5237.8721651
[86] loss: 5237.8721651
[87] loss: 5237.8721651
[88] loss: 5237.8721651
[89] loss: 5237.8721651
[90] loss: 5237.8721651
[91] loss: 5237.8721651
[92] loss: 5237.8721651
[93] loss: 5237.8721651
[94] loss: 5237.8721651
[95] loss: 5237.8721651
[96] loss: 5237.8721651
[97] loss: 5237.8721651
[98] loss: 5237.8721651
[99] loss: 5237.8721651
[100] loss: 5237.8721651
[101] loss: 5237.8721651
[102] loss: 5237.8721651
[103] loss: 5237.8721651
[104] loss: 5237.8721651
[105] loss: 5237.8721651
[106] loss: 5237.8721651
[107] loss: 5237.8721651
[108] loss: 5237.8721651
[109] loss: 5237.8721651
[110] loss: 5237.8721651
[111] loss: 5237.8721651
[112] loss: 5237.8721651
[113] loss: 5237.8721651
[114] loss: 5237.8721651
[115] loss: 5237.8721651
[116] loss: 5237.8721651
[117] loss: 5237.8721651
[118] loss: 5237.8721651
[119] loss: 5237.8721651
[120] loss: 5237.8721651
[121] loss: 5237.8721651
[122] loss: 5237.8721651
[123] loss: 5237.8721651
[124] loss: 5237.8721651
[125] loss: 5237.8721651
[126] loss: 5237.8721651
[127] loss: 5237.8721651
[128] loss: 5237.8721651
[129] loss: 5237.8721651
[130] loss: 5237.8721651
[131] loss: 5237.8721651
[132] loss: 5237.8721651
[133] loss: 5237.8721651
[134] loss: 5237.8721651
[135] loss: 5237.8721651
[136] loss: 5237.8721651
[137] loss: 5237.8721651
[138] loss: 5237.8721651
[139] loss: 5237.8721651
[140] loss: 5237.8721651
[141] loss: 5237.8721651
[142] loss: 5237.8721651
[143] loss: 5237.8721651
[144] loss: 5237.8721651
[145] loss: 5237.8721651
[146] loss: 5237.8721651
[147] loss: 5237.8721651
[148] loss: 5237.8721651
[149] loss: 5237.8721651
[150] loss: 5237.8721651
[151] loss: 5237.8721651
[152] loss: 5237.8721651
[153] loss: 5237.8721651
[154] loss: 5237.8721651
[155] loss: 5237.8721651
[156] loss: 5237.8721651
[157] loss: 5237.8721651
[158] loss: 5237.8721651
[159] loss: 5237.8721651
[160] loss: 5237.8721651
[161] loss: 5237.8721651
[162] loss: 5237.8721651
[163] loss: 5237.8721651
[164] loss: 5237.8721651
[165] loss: 5237.8721651
[166] loss: 5237.8721651
[167] loss: 5237.8721651
[168] loss: 5237.8721651
[169] loss: 5237.8721651
[170] loss: 5237.8721651
[171] loss: 5237.8721651
[172] loss: 5237.8721651
[173] loss: 5237.8721651
[174] loss: 5237.8721651
[175] loss: 5237.8721651
[176] loss: 5237.8721651
[177] loss: 5237.8721651
[178] loss: 5237.8721651
[179] loss: 5237.8721651
[180] loss: 5237.8721651
[181] loss: 5237.8721651
[182] loss: 5237.8721651
[183] loss: 5237.8721651
[184] loss: 5237.8721651
[185] loss: 5237.8721651
[186] loss: 5237.8721651
[187] loss: 5237.8721651
[188] loss: 5237.8721651
[189] loss: 5237.8721651
[190] loss: 5237.8721651
[191] loss: 5237.8721651
[192] loss: 5237.8721651
[193] loss: 5237.8721651
[194] loss: 5237.8721651
[195] loss: 5237.8721651
[196] loss: 5237.8721651
[197] loss: 5237.8721651
[198] loss: 5237.8721651
[199] loss: 5237.8721651
[200] loss: 5237.8721651
[201] loss: 5237.8721651
[202] loss: 5237.8721651
[203] loss: 5237.8721651
[204] loss: 5237.8721651
[205] loss: 5237.8721651
[206] loss: 5237.8721651
[207] loss: 5237.8721651
[208] loss: 5237.8721651
[209] loss: 5237.8721651
[210] loss: 5237.8721651
[211] loss: 5237.8721651
[212] loss: 5237.8721651
[213] loss: 5237.8721651
[214] loss: 5237.8721651
[215] loss: 5237.8721651
[216] loss: 5237.8721651
[217] loss: 5237.8721651
[218] loss: 5237.8721651
[219] loss: 5237.8721651
[220] loss: 5237.8721651
[221] loss: 5237.8721651
[222] loss: 5237.8721651
[223] loss: 5237.8721651
[224] loss: 5237.8721651
[225] loss: 5237.8721651
[226] loss: 5237.8721651
[227] loss: 5237.8721651
[228] loss: 5237.8721651
[229] loss: 5237.8721651
[230] loss: 5237.8721651
[231] loss: 5237.8721651
[232] loss: 5237.8721651
[233] loss: 5237.8721651
[234] loss: 5237.8721651
[235] loss: 5237.8721651
[236] loss: 5237.8721651
[237] loss: 5237.8721651
[238] loss: 5237.8721651
[239] loss: 5237.8721651
[240] loss: 5237.8721651
[241] loss: 5237.8721651
[242] loss: 5237.8721651
[243] loss: 5237.8721651
[244] loss: 5237.8721651
[245] loss: 5237.8721651
[246] loss: 5237.8721651
[247] loss: 5237.8721651
[248] loss: 5237.8721651
[249] loss: 5237.8721651
[250] loss: 5237.8721651
[251] loss: 5237.8721651
[252] loss: 5237.8721651
[253] loss: 5237.8721651
[254] loss: 5237.8721651
[255] loss: 5237.8721651
[256] loss: 5237.8721651
[257] loss: 5237.8721651
[258] loss: 5237.8721651
[259] loss: 5237.8721651
[260] loss: 5237.8721651
[261] loss: 5237.8721651
[262] loss: 5237.8721651
[263] loss: 5237.8721651
[264] loss: 5237.8721651
[265] loss: 5237.8721651
[266] loss: 5237.8721651
[267] loss: 5237.8721651
[268] loss: 5237.8721651
[269] loss: 5237.8721651
[270] loss: 5237.8721651
Finished Training
The r2m value for this run is:  nan
The AUPR for this run is:  0.665
The Concordance Index (CI) for this run is:  0.5
The Mean Squared Error (MSE) for this run is:  44.127
r2m std is:  nan
AUPR std is:  0.0
CIs std is:  0.0
Best r2m was:  0.4261557731478642
Best parameters were: [110, 0.0088, 270]


PS:

Read file <stderr_pkd_d1_p1.log> for stderr output of this job.

